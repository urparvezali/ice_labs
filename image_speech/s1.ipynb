{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ea6229",
   "metadata": {},
   "source": [
    "### Speech to Text conversion using Google api\n",
    "#### Theory\n",
    "Speech recognition is a technology that enables machines to interpret and process human speech into text. It involves the use of algorithms and models to analyze audio signals, extract features, and map them to corresponding linguistic representations. The process typically includes the following steps:\n",
    "\n",
    "1. **Audio Signal Acquisition**: Capturing audio input using a microphone or other recording devices.\n",
    "2. **Preprocessing**: Removing noise and normalizing the audio signal for better accuracy.\n",
    "3. **Feature Extraction**: Extracting relevant features such as Mel-Frequency Cepstral Coefficients (MFCCs) or spectrograms from the audio signal.\n",
    "4. **Recognition**: Using machine learning models, such as Hidden Markov Models (HMMs) or neural networks, to map features to text.\n",
    "5. **Postprocessing**: Refining the output to improve readability and accuracy.\n",
    "\n",
    "**In this lab, the `speech_recognition` library is used to implement speech-to-text functionality. This library provides tools for capturing audio, processing it, and recognizing speech using various APIs like Google Speech Recognition.**\n",
    "\n",
    "#### Objectives\n",
    "1. To understand the fundamentals of speech recognition and its workflow.\n",
    "2. To implement a speech recognition system using the `speech_recognition` library in Python.\n",
    "3. To capture audio input from a microphone and preprocess it for recognition.\n",
    "4. To utilize Google Speech Recognition API for converting speech to text.\n",
    "5. To analyze and interpret the recognized text for further applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9be09157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e74fd321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:567:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm_dsnoop.c:567:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating microphone for ambient noise...\n",
      "Recording for 5 secs...\n",
      "Processing audio...\n",
      "Recognized text:\n",
      "my favourite subject is digital image and speech processing\n"
     ]
    }
   ],
   "source": [
    "duration = 5\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "microphone = sr.Microphone()\n",
    "\n",
    "print(\"Calibrating microphone for ambient noise...\")\n",
    "with microphone as mic:\n",
    "\trecognizer.adjust_for_ambient_noise(mic, 2)\n",
    "\trecognizer.dynamic_energy_threshold = True\n",
    "\trecognizer.pause_threshold = 0.8\n",
    "\n",
    "\tprint(f\"Recording for {duration} secs...\")\n",
    "\taudio_data = recognizer.record(mic, duration=duration)\n",
    "\n",
    "print(\"Processing audio...\")\n",
    "try:\n",
    "\tout = recognizer.recognize_google(audio_data, show_all=False)\n",
    "\n",
    "\tprint(\"Recognized text:\")\n",
    "\tprint(out)\n",
    "except sr.UnknownValueError:\n",
    "\tprint(\"No speech detected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
